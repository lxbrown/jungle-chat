# On scalability

This app, as mentioned in the README, is intended primarily to be for the experience of turning an idea into an application - one with a responsive UI, an API layer, and object persistence. And finally, generally and consistently available on a public domain. While it's obvious millions won't be flocking to this application, I wanted to design it in such a way that the plan for scaling, at least in the short term, could be accomplished with minimal effort.

## Client connections

I chose [Node.js](https://nodejs.org/) as a server framework because Node is exceptional when it comes to a lightweight, low compute, and high throughput application - exactly what comes to mind when you think "messaging app". Using Node, however, does come with its limitations. In conjunction with the real-time event-based communication package [socket.io](https://socket.io/), all users are effectively being funneled through one thread. This system will perform well right up until the moment it doesn't. Then it'll grind to a halt.

Based on [this analysis](http://drewww.github.io/socket.io-benchmarking/), the author found it's reasonable to expect that failure to happen somewhere between 9,000 and 10,000 concurrent events, depending on the number of client connections and the capacity of the machine. The Heroku dyno I'm using will realistically hit that limit at a different threshold, but it serves as a nice order of magnitude estimate for us to start with. If we want to go higher, we'll need more than one Node server operating and ready to receive requests. This can be relatively easily accomplished though the use of [Redis](https://redis.io/). socket.io can be [configured to use Redis](https://socket.io/docs/v3/using-multiple-nodes/#Passing-events-between-nodes) using the publish/subscribe messaging paradigm. That way, we can allow clients connected to different Node servers to receive updates as if they were connected to the same machine. Configuring Heroku to run multiple dynos is a part of their Standard (paid) package, listed at \$25-\$50 per dyno per month. Given that this application isn't anywhere near the limits of a single (free) dyno, I don't have any plans to set up Redis and add support for multiple server connections. But I've found it quite useful and educational to research HOW it might be done!

## Persistence and data retrival

At this point, we've figured out a rough plan to expand our server framework so it's no longer limiting the number of clients we can support. One point I'd briefly like to touch on is the persistence of messages and how this app will ensure quick retrival for messages (up to a point). In complete honesty, choice of a database and database architecture was influenced by [this blog post](https://blog.discord.com/how-discord-stores-billions-of-messages-7fa6ec7ee4c7) by the CTO of Discord. I expect if this app were to grow, it would follow a very similar progression. MongoDB has proven to be great for getting a NoSQL database up and running quickly, with as little overhead as possible. With a single index on the room id and message timestamp, we can expect this app to scale well for some time. As I was deciding on a schema, a good friend of mine made a comment with respect to NoSQL databases that really helped make it stick - design your schema around the questions you need to ask (backed up by [MongoDB's documentation](https://www.mongodb.com/nosql-explained/data-modeling)). In this case, the most frequently asked question is for the last X messages (with an offset) for a certain room, so it makes sense to prioritize indexing that specific query. There are a few others, like finding a room's metadata by its short name, where it may make sense to index in the future, but for the (presently) 4 rooms, that's overkill. I have less to say here as it comes to scalability, but it's certainly fun to think about how to take something that's serving 0-5 users, and build it up so it's capable of handling orders of magnitude more!